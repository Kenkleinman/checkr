---
title: "Checking Code Answers"
author: "Daniel Kaplan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r include = FALSE}
library(ggplot2)
library(dplyr)
library(checkr)
```
[[NOTE in draft: Remember to explain `eval()` used as part of the function-call pattern, e.g. `"rep(eval(1:4))"` as a reference pattern will match `"rep(c(1,2,3,4))"` as a submission.]]
 

In tutorial systems such as <DataCamp.com> or the `tutor` package in R, problems are posed that call for the student to write an answer in R code. This package provides a system for checking whether that R code has done what's required and, if not, where the problem might fall.

## A trivial example: 2 + 2

To illustrate, consider this trivial problem: 

> Write the code to add two and two. 

Of course, we expect the student to submit `2 + 2` as the response. But they might have

* submitted nothing
* submitted something like `3 + 1`
* submitted something like `2 / 2`

This package allows you to write test statements that

1. allow the values produced by the code to be tested against a specified solution and 
2. examine the student's submission to make sure the code was of the submitted form.

A tutorial system will typically collect the student code submissions as text, and may evaluate the code in order to verify that it runs.  Here are a few different possible submissions for the `2 + 2` problem:

```{r}
# three possible submissions to the problem
submission_1 <- "2 + 2" # correct
submission_2 <- "2 / 2" # right arguments but wrong function
submission_3 <- "3 + 2" # right function but wrong arguments
```

One approach to checking these submissions is to compare them to the correct character string, that is, `"2 + 2"`. But if there is not a match, we can't give any guidance other than "that's wrong."

Here are some tests from `checkr` that are relevant. Each test takes the form of a pattern and a message to return if that pattern is not found.
```{r}
library(checkr)
test_1 <- fcall("whatever + whatever", "need to use addition (+)")
test_2 <- fcall("2 + whatever", "first argument should be 2")
test_3 <- fcall("whatever + 2", "second argument should be 2")
```

In a tutor document, the R/Markdown to set up the problem would look like this:

    1. Write a statement to calculate two plus two.
    
    ```{r, example-0, exercise = TRUE}
    # your code goes here
    ```

To tell `tutor` to use the `checkr` tests, the `setup` chunk at the beginning of the Rmd file should set the `exercise.checker` chunk option to be the `run_tests()` function from the `checkr` package.

    ```{r setup, include=FALSE}
    library(tutor)
    library(checkr)

    knitr::opts_chunk$set(exercise.checker =     checkr::checkr_tutor)
    ```

When the student presses the "submit" button in the `tutor` code window, the student's code is sent off for checking.  You place the test statements in the problem's `-check` chunk, like this:

    ``{r example-0-check, echo=FALSE}
    test_1 <- fcall("whatever + whatever",  
                "need to use addition (+)")
    test_2 <- fcall("2 + whatever", 
                "first argument should be 2")
    test_3 <- fcall("whatever + 2", 
                "second argument should be 2")
    USER_CODE %>% test_1 %>% test_2 %>% test_3
    ```

The `tutor` system will call `checkr_tutor()` with information about the various chunks relating to the problem. In turn, `run_tests()` will evaluate the code in the `-check` chunk. The `USER_CODE` object is created by `run_tests()` to provide access to the code submitted by the user.

The tests here are called "locator tests." All three of `test_1`, `test_2` and `test_3` here are constructed by the `fcall()` function in `checkr`. The `fcall()` function takes as it's first argument a pattern to look for in the submitted code. The second argument is a message to give if the pattern is *not* found; this is called the "failure message." 

The tests are called in the order implied by the `%>%` pipes. Whichever test in that sequence fails first will set the message returned to the `tutor` system for display to the student. If no test fails, the `tutor` is told that the student's code passes.

In designing the tests for the "two plus two" problem, I decided that the first thing I want to check for is that the `+` function is being used, but without regard to the value of the two arguments. The second test imposes an additional restriction: the first argument to `+` should be 2. Similarly for the third test.

Within a tutor document, these tests would be activated when the student presses the submit button. For this static vignette, it's inconvenient to run the tests in the interactive way. I want to be able to comment on the results of the test. So, just for the purposes of this vignette, I'll replace the `tutor` system with two functions: 

1. `capture.code()` simulates what `tutor` does with the student's submitted code to hand it off to `checkr`.
2. `show_results()` prints the failure message. An empty failure message, `""`, means the tests were passed.

You should **not** use either of these functions in an active `tutor` Rmd document.

```{r echo = FALSE}
show_results <- function(test_output) {
  if (test_output$passed) return("Passed!")
  else return(paste("Sorry, but", test_output$message))
}
```

Now to run the various tests on the different submissions:
```{r}
capture.code(submission_1) %>% 
  test_1 %>% 
  show_results
capture.code(submission_2) %>% 
  test_1 %>% 
  show_results
```

Submission 1 passed, as expected. Submission 2 failed. The failure message indicates what's wrong with the code.

You may be surprised to see that submission 3, which is wrong, nonetheless passes the test
```{r}
capture.code(submission_3) %>% 
  test_1 %>% 
  show_results
```
This is because `test_1` has been set up to check that the right function is being used, and not to check the arguments. For checking the arguments, `test_2` and `test_3` can be used.


In actual use, tests can be strung together in a sequence. Whatever test in the sequence is first to fail will produce the output of the whole string. For example:
```{r}
capture.code(submission_3) %>% 
  test_1 %>% test_2 %>% test_3 %>% 
  show_results
```
`test_1` was passed, but `test_2`, which checks to see that the first argument is `2`, failed. `test_3` was not even run, because `test_2` already failed. 

The importance of this for test writers is that you can customize the failure message for late tests in the sequence with the knowledge that the earlier tests have passed. 

For instance, the failure message for `test_2` is ""first argument should be 2." The message doesn't have to concern whether the `+` function was used. Because `test_2` follows `test_1` in the sequence, we know that `+` was used in the student's submission.

## Matching values

The R statements in the student's submission, presumably, produce values. These might be assigned a name with `<-` or they might be unnamed. Each complete statement produces a value.

The tests shown above for the "two plus two" problem don't actually require that the value produced be 4. For example, the following submission, `2 + 2 + 2` does not produce a value of 4. Nonetheless, it passes the tests:
```{r}
capture.code("2 + 2 + 2") %>% 
  test_1 %>% test_2 %>% test_3 %>% 
  show_results
```
It's tempting to apply a test that says, "and nothing more."  I've rejected this strategy for the present, noting that sometimes valid statement (e.g. `I(2 + 2)`) will have more than the test writer expected. Instead, you can test the values of the results produced by the student code.

```{r}
# these values are provided by tutor
USER_CODE   <- capture.code("2 + 2 + 2")
SOLN_CODE   <- capture.code("2 + 2")

# the -check chunk contents would look like
soln_test(USER_CODE, SOLN_CODE,
             res = final_(),
             same_num(res)) %>%
  show_results()
```
The `soln_test()` function from `checkr` compares the values produced by the student's code and the values produced by code provided by the test writer in a `-solution` chunk. `USER_CODE` and `SOLN_CODE` convey the contents of the submission and solution chunks, respectively. 

The next argument to `soln_test()` uses a function `final_()`, which looks for the *last* value produced by the student and by the solution code. In this example, there's only one value, but in general there may be multiple values produced by submitted code. Whatever that last value be, and regardless of whether the student's or solution code assigned a name to the value, the argument name will be assigned to that value for future reference.

The final argument to `soln_test()` refers to the name `ref` created in the previous argument. The `same_num()` function compares the `ref` value in the student and the solution code. 

Later, we'll show examples using `soln_test()` that can deal with more complicated structure in the student and solution code. For instance, you can have as many reference-named values and comparison tests as you like, but that's hardly needed in this simple example.


## Framework for testing

Before it can be tested, the student answer must run, even if the answer is not correct. Parsing errors and run-time errors are absorbed by the `tutor` system, so any code with such errors will not be handed over to `checkr` for evaluation.

`Checkr` examines code one command line at a time. A command line is a complete piece of R code that generates a value, such as would be given in the console and evaluated when "return" is pressed. Here are some examples of statements:

* `x <- 7`
* `library(ggplot2)`
* `lm(mpg ~ hp, data = mtcars)`

Note that assignment of a name to a value, e.g. `x <- 7`, is part of the statement. 

At present, `checkr` tests are designed around command lines like the above.
When `magrittr` pipes are used, all the commands piped together constitute one statement. `checkr` will break such chains into individual statements, each having the contents between successive pipes.

Note that when curly braces are included in code, a command line is more inclusive than many people would think at first glance. For instance, `for` loops constitute a single a command line. The following chunk has only one command line: 

```r
for (k in 1:length(vec)) { 
  x <- cos(vec[k])
  sum <- sum + x
}
```

The same is true for `if` statements, such as:

```r
if (x > 0) {
  y <- cos(x)
} else {
  z <- sin(x)
}
```

Function definition with `function` also involves a single statement:

```r
funnel <- function(x, width=3) {
  ifelse(abs(x) > width, abs(x), -width)
}
```

In the future, we anticipate providing `checkr` tests that work with such constructions.



## Solution-matching tests and location tests

There are two basic kinds of `checkr` tests: solution-matching tests and location tests.

1. In a **solution-matching test**, a comparison is made between a solution provided by the problem author and the student's submitted code. Solution-matching tests are contained within the `soln_test()` function. 
2. In a **location test**, there is no reference to the author's solution. Instead, the test looks for patterns within the student's code. Location tests start with `USER_CODE %>% [one or more tests]`.

A `-check` chunk is composed of one or more test: solution-matching tests can be freely intermixed with location tests.

## Location tests

Location tests specify a pattern that is expected to be in the student code. Each location test either fails or identifies a single command line in the code being examined that matches the specified pattern. Location tests look through the command lines in a student answer to find the match. There are several ways to specify patterns:

- a character string (or regex) matches 
- a specified function (and, optionally, specified arguments) is called
- assignment to a name is done by the statement.

Location tests are often specified as sequences of tests, written

    USER_CODE %>% test_1 %>% test_2 ... and so on

The tests are run from left to right. Any test failing causes the test to terminate. The failure message from the whole sequence will be the failure message from the test that failed. If a test passes, the next test in the sequence is applied, and so on. 

Each passing test records the particular command line that matched the pattern. Subsequent tests can be directed to look for matches before, after, or within the command line that matched the previous test. See the location-qualifier functions \code{then}, \code{previously}, and \code{within}. Of course, you need not use a location qualifier, in which case subsequent tests will look at *all* command lines.

There are location tests that allow you to test a value generated by the code. The simplest is \code{check_value}, which looks at the value of the whole command line. A previous locator test should have identified the particular line whose value is to be tested.  For example:

```{r}
USER_CODE <- capture.code("x <- 7 + 3\n sin(x)")
test_1 <- fcall("sin(whatever)", "you didn't use sin().")
test_2 <- check_value(match_number(sin(10), "something's wrong with the sin() line."))
USER_CODE %>%
  test_1 %>% test_2 %>%
  show_results
```
  
Another kind of value-checking location test looks for the value of an argument to a function. The location specifier must include a \code{grab_this} to identify the particular argument to be captured. For instance:

```{r}
test_a <- fcall("whatever + whatever", "remember to use +") # regular location test
test_b <- check_argument("grab_this + whatever", 
                         match_number(17, tol = 0.1))
USER_CODE %>%
  test_a %>% test_b %>%
  show_results
```

## Example: Testing assignment

Consider a problem like this:

> Assign the name `x` to the results of the calculation $\sqrt{7}$.

There are several things to be checked here:

1. That a name was assigned to an object.
2. That the name was `x`
3. That `sqrt()` was called.
4. That 7 was the argument to `sqrt()`.

It's the author's choice whether to test all these things. Here are some locator test sequences that an author might choose among.

```{r}
USER_CODE <- capture.code("xx <- sin(7)") # wrong in so many ways!
test_1 <- fcall("sqrt(whatever)", "use the sqrt() function.")
test_2 <- assigns_to("x")
test_3 <- check_argument("sqrt(grab_this)", match_number(7))
```

Which of these tests should come first? It depends on the points the author wants to emphasize. For example, she might want to know first whether assignment  was used.
```{r}
USER_CODE %>% test_2 %>% test_1 %>% test_3 %>% show_results
```
Or, the author might want to check first that the `sqrt()` function was used.
```{r}
USER_CODE %>% test_1 %>% test_3 %>% test_2 %>% show_results
```


## Creating and debugging tests

Note that in the examples, the location tests are all created and named *before* being used in the `USER_CODE %>% ...` checking line. Each test is implemented as an unevaluated function.

You might **incorrectly** write
```r
USER_CODE %>% fcall("whatever + whatever", "remember to use +")
```
This is not a check statement. Instead, the statement passes `USER_CODE` to the `fcall()` function. But `fcall()` doesn't take user code as an input. Rather, `fcall()`'s first argument should be the pattern to be matched. The output of `fcall()` is another function. That function *does* take user code as input.

In debugging a single test such as `test_a`, you should call `debug(test_a)`. This "functional programming" style has the potential to be confusing to many users.

## A richer example

Here's a problem that's more difficult: Using `ggplot()`, make a scatterplot of miles-per-gallon versus horsepower in the `mtcars` data.

Let's look at these possible submissions:

```{r}
submission_1 <- "ggplot(mtcars, aes(x = mpg, y = hp)) + geom_point()" # Wrong!
submission_2 <- "ggplot(mtcars, aes(x = hp, y = mpg)) + geom_line()" # Wrong!
submission_3 <- "ggplot(mtcars, aes(y = mpg, x = hp)) + geom_point()" # right
submission_4 <- "ggplot(mtcars) + geom_point(aes(y = mpg, x = hp))" # also right
submission_5 <- c(
"my_cars <- mtcars",
"ggplot(my_cars, aes(y = mpg, x = hp)) + geom_point()")
submission_6 <- c(
"my_cars <- mtcars %>% select(mpg, hp)",
"ggplot(my_cars, aes(y = mpg, x = hp)) + geom_point()")
```

Submission 1 has the roles of the variables `mpg` and `hp` reversed from the problem statement. Submission 2 uses `geom_line()` instead of the required `geom_point()`. Submissions 3 and 4 will all create the specified plot, but each is arranged in a different way.

Here are some tests. Remember, the second argument is the message to return if the test *fails*.
```{r}
library(ggplot2)
test_1 <- fcall("aes(x = hp, y = whatever)", "variable 'hp' goes on the x axis")
test_2 <- fcall("aes(y = mpg, x = whatever)", "variable 'mpg' goes on the y axis")
test_3 <- fcall("geom_point()", "include a 'geom_point()' layer")
test_4 <- in_statements("mtcars") 
test_5 <- fcall("ggplot(data = whatever)", "no data handed to ggplot()")
test_6 <- check_argument("ggplot(data = grab_this)", test = match_class("data.frame"))
test_7 <- check_argument("ggplot(data = grab_this)", match_data_frame(mtcars))
test_8 <- check_argument("ggplot(data = grab_this)", 
                         match_data_frame(mtcars, hint = TRUE))
test_9 <- check_argument("ggplot(data = grab_this)",
                         match_data_frame(
                           mtcars %>% select(hp, mpg, carb), 
                           hint = TRUE))
```

We'll chain these seven tests together and see the results for the different submissions.

```{r}
capture.code(submission_1) %>% 
  test_1 %>% test_2 %>% test_3 %>% test_4 %>% test_5 %>% test_6 %>% test_7 %>% 
  show_results
capture.code(submission_2) %>%
  test_1 %>% test_2 %>% test_3 %>% test_4 %>% test_5 %>% test_6 %>% test_7 %>%
  show_results
capture.code(submission_3) %>% 
  test_1 %>% test_2 %>% test_3 %>% test_4 %>% test_5 %>% test_6 %>% test_7 %>% 
  show_results
capture.code(submission_4) %>%
  test_1 %>% test_2 %>% test_3 %>% test_4 %>% test_5 %>% test_6 %>% test_7 %>%
  show_results
```

These examples show passes and fails when checking the value of an argument to a function.

```{r}
capture.code(submission_5) %>%
  test_5 %>% test_7 %>%
  show_results
capture.code(submission_6) %>%
  test_5 %>% test_7 %>%
  show_results
capture.code(submission_6) %>%
  test_5 %>% test_8 %>%
  show_results
capture.code(submission_6) %>%
  test_5 %>% test_9 %>%
  show_results

```
  

## Checking values

Each command produces a value. You have access to these, both named and unnamed. 

For instance, this command does some arithmetic and creates a `ggplot` object.

```{r}
submission_1 <- "
3 + 5
ggplot(mtcars, aes(y = mpg, x = hp)) + geom_point()" 
```

A simple test for this is:
```{r}
test_1 <- in_values(match_class("ggplot"))
capture.code(submission_1) %>%
  test_1 %>%
  show_results
```

But if we were looking for a `lattice` graphics object, the submission fails:
```{r eval = FALSE}
test_2 <- in_values(match_class("lattice"))
capture.code(submission_1) %>%
  test_2 %>%
  show_results
```

If either would suffice ...
```{r}
test_3 <- either(test_1, test_2)
capture.code(submission_1) %>%
  test_3 %>%
  show_results
```

Suppose that we want to check that a number near 8 is created ...
```{r}
test_4 <- in_values(match_number(8, range = c(7.9, 8.1)))
capture.code(submission_1) %>% test_4 %>%
  show_results
```

## Checking the value itself


A sequence of odd numbers from 11 to 31 (inclusive) using the colon operator.

```{r}
submission_1 <- capture.code("seq(11, 31, by = 2)") # right value, but not what was asked
submission_2 <- capture.code("11 + 2*(0:10)") # right
submission_3 <- capture.code("11 + 2*(1:11)") # uses colon, but wrong result

```

```{r}
test_1 <- fcall("whatever : whatever", "you didn't use the colon operator")
test_2 <- check_value(match_vector(seq(11, 31, by = 2), hint = TRUE))

submission_1 %>% test_1 %>% test_2 %>% show_results
submission_2 %>% test_1 %>% test_2 %>% show_results
submission_3 %>% test_1 %>% test_2 %>% show_results
```



Suppose we ask the student to construct a somewhat complicated object that we want to run some checks on. For instance, "Construct a model of `mpg` versus `hp` using `wt` as a covariate."

```{r}
submission_1 <- capture.code("lm(mpg ~ hp, data = mtcars)")  # wrong
submission_2 <- capture.code("lm(mpg ~ hp + wt, data = mtcars)") # right
submission_3 <- capture.code("lm(mpg ~ wt, data = mtcars)") # wrong
```

```{r}
test_1 <- fcall("lm(data = mtcars)", "use lm() on mtcars data")
test_2 <- check_value(function(x) {'wt' %in% names(coef(x))}, 
                      "what about the covariate wt?")
test_3 <- check_value(function(x) {all(c("hp", "wt") %in% names(coef(x)))}, 
                      'include both hp and the covariate as explanatory variables')
test_4 <- check_argument("lm(formula = grab_this)", match_formula(mpg ~ hp + wt))
```

```{r eval = FALSE}
submission_1 %>% test_1 %>% test_2 %>% test_3 %>% show_results
submission_2 %>% test_1 %>% test_2 %>% test_3 %>% show_results
submission_3 %>% test_1 %>% test_2 %>% test_3 %>% show_results
submission_1 %>% test_1 %>% test_4 %>% show_results
submission_3 %>% test_1 %>% test_4 %>% show_results
```

## Comparing to a given solution

IN DRAFT. TALK ABOUT `closest_to("what")`, which finds the value in the user code that's closest to the value in the solution code identified by the <what> string. The <what> string *must* be a parsable command, but does not need to be the whole line of code. Alternatively, you can give `closest_to()` an unquoted name, corresponding to some named object produced by the solution code.

Often, perhaps most of the time, the question author will provide an example solution. The `soln_test()` function lets you compare the values generated by the solution to the values generated by the user's code.

To illustrate, let's construct by hand the `USER_CODE` and `SOLN_CODE` contents that get produced from the question chunks in a `tutor` document.
```{r}
USER_CODE <- capture.code("2 + 3")
SOLN_CODE <- capture.code("2 + 2")
soln_test(USER_CODE, SOLN_CODE,
             res = in_statements("2 *\\+", regex = TRUE),
             same_num(res)) %>% 
  show_results
```
The first two arguments to `soln_test()` are always the user code and the solution code in that order. The following arguments to `soln_test()` are either named or unnamed. 

Named arguments -- e.g. `res = instatements(regex="2 *\\+")` -- are often set to be locator statements. The name itself will be used to refer to the value for the command found by the locator statement. Alternatively, named arguments can be used to calculate some value from those already located and named.

Unnamed arguments -- e.g. `same_num(res)` -- are a comparison test selected from the `same_()` family of tests provided by `checkr`. 

In operation, `soln_test()` extracts out the values from the user code and the solution code for the command that passes the locator statement. The comparison tests are then run to compare the user values and the solution values.

You can compute elements from the named values. For instance, here we compare not the result itself but the absolute value of the result. Thus, the user code, which does not match the solution code, still passes the `same_num()` test, since the value $-4$ computed by the user passes the test.

```{r}
USER_CODE <- capture.code("2 + -6")
SOLN_CODE <- capture.code("2 + 2")
soln_test(USER_CODE, SOLN_CODE,
             res = in_statements("2 *\\+", regex = TRUE),
             same_num(abs(res))) %>% 
  show_results
```

The point of having such transformations -- e.g. `abs()` in the above example -- is to enable the test writer to compare complex objects like models using simple comparisons. For instance, suppose the user is asked to construct a model based on `mtcars`:
```{r eval = FALSE}
USER_CODE <- capture.code("mod <- lm(mpg ~ hp + carb, data = mtcars)")
SOLN_CODE <- capture.code("mod <- lm(mpg ~ hp * carb, data = mtcars)")
soln_test(USER_CODE, SOLN_CODE,
             res = assigns_to("mod"),
             same_vec(coef(res))) %>% 
  show_results
```



## Magrittr pipelines

Magrittr pipelines are translated into a sequence of commands. For instance,
```
foobar <- mtcars %>% filter(mpg > 15) %>% select(mpg)
```
will be evaluated as if it were
```
filter(mtcars, mpg > 15) -> ..tmp1..
select(..tmp1.., mpg) -> foobar
```

This allows tests to be constructed as if each step in the chain were a separate command; the test statements can be constructed in the ordinary way. Do remember that the first argument to `dplyr` data verbs is `.data =`.


```{r eval = FALSE}
submission_1 <- capture.code("foobar <- mtcars %>% filter(mpg > 15)")
test_1 <- fcall("filter()", "should call filter()")
test_2 <- check_argument("mpg > grab_this", match_number(15))
test_2A <- check_argument("mpg > grab_this", match_number(16))
test_3 <- check_argument("filter(.data = grab_this)", match_data_frame(iris, hint = TRUE))
submission_1 %>% test_1 %>% test_2 %>% test_3 %>% show_results
submission_1 %>% test_1 %>% test_2A %>% test_3 %>% show_results

```

STILL NEED TO HANDLE INTERNAL CHAINS and EXPLICIT "dot" arguments.

This is not working. I think I need a new check_argument_symbol() that won't try to evaluate the symbols.
```{r}
submission_2 <- capture.code("mtcars %>% filter(mpg > 15) %>% group_by(cyl) %>% summarise(mmpg = mean(mpg))")
test_4 <- fcall("group_by()")
test_5 <- check_argument("group_by(.data = whatever, grab_this)", function(x) x)
submission_2 %>% test_4 %>% test_5 %>% show_results
```
